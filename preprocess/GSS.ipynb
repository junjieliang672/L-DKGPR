{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GSS data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The official website of this data:\n",
    "http://gss.norc.org/About-The-GSS\n",
    "\n",
    "Preprocessing:\n",
    "\n",
    "1. The original file is very large, with lots of repeated columns. All repeated columns are removed.\n",
    "1. Columns with more than half of the values as nans are removed.\n",
    "1. All categorical features are expended using onehot encoding.\n",
    "1. The observation is defined by the year of the survey.\n",
    "1. The prediction outcome is the self-reported GENERAL HAPPINESS of the subject, where more than 80% of them are positive. Labels are unbalanced.\n",
    "\n",
    "Statistics:\n",
    "\n",
    "records: 59599\n",
    "\n",
    "features: 1394 (including subject id, observation id and outcome)\n",
    "\n",
    "subjects: 4510\n",
    "\n",
    "observations: 30 (ranging from 1972 - 2014)\n",
    "\n",
    "density: 44.05%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# driveLoc = \"F:/onedrive\"\n",
    "# driveLoc = \"/Users/jul672/Desktop/OneDrive\"\n",
    "driveLoc = \"C:/Users/jokit/OneDrive\"\n",
    "fileLoc = driveLoc+'/phd projects/The General Social Survey (GSS)/'\n",
    "file = fileLoc + 'gss.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def getColumnsWithLabel(x):\n",
    "    target = []\n",
    "    for each in x:\n",
    "        if each.endswith('labels'):\n",
    "            target.append(each.split('_')[0])\n",
    "        elif re.search('labels.*$',each):\n",
    "            sp1 = each.split('_')\n",
    "            sp2 = sp1[1].split('.')\n",
    "            target.append(sp1[0]+'.'+sp2[1])\n",
    "    return target\n",
    "\n",
    "def dropColumnsByName(x):\n",
    "    # only keep columns with label and ends with label\n",
    "    return not (x in dropColumns)\n",
    "\n",
    "def dropColumnsByCountingNa(x):\n",
    "    l = x.size\n",
    "    na_c = x.isna().sum()\n",
    "    iap_c = (x == 'IAP').sum()\n",
    "    missing = na_c + iap_c\n",
    "    if missing / l > .5: # more than half of the values are nas\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "\n",
    "def dropColumnsByCountingIAP(x):\n",
    "    l = x.size\n",
    "    iap_c = np.sum(['IAP' in str(each).split(',') for each in x])\n",
    "    if iap_c / l > .5: # more than half of the values are nas\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "\n",
    "def dropNotApplicable(x):\n",
    "    l = x.size\n",
    "    nappl = (x == 'Not applicable').sum()\n",
    "    if nappl / l > .5: # more than half of the values are nas\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "\n",
    "def dropNoISSP(x):\n",
    "    l = x.size\n",
    "    nissp = (x == 'IAP-NO ISSP').sum() + (x == 'NO ISSP').sum()\n",
    "    if nissp / l > .5: # more than half of the values are nas\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "\n",
    "def dropUncodeable(x):\n",
    "    l = x.size\n",
    "    nissp = (x == 'UNCODEABLE & IAP').sum()\n",
    "    if nissp / l > .5: # more than half of the values are nas\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "    \n",
    "def renameColumns(x):\n",
    "    return x.strip()\n",
    "# data = data.rename(renameColumns, axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter the columns\n",
    "# data = pd.read_csv(file,nrows = 10000,usecols=useCols)\n",
    "# dropColumns = getColumnsWithLabel(data.columns.values)\n",
    "# data1 = data.loc[:,list(map(dropColumnsByName,data.columns.values))]\n",
    "# # useCols = data1.columns.values\n",
    "# keep1 = data1.apply(dropColumnsByCountingNa,axis=0)\n",
    "# data2 = data1.loc[:,keep1]\n",
    "# keep2 = data2.apply(dropColumnsByCountingIAP,axis=0)\n",
    "# data3 = data2.loc[:,keep2]\n",
    "# keep3 = data3.apply(dropNotApplicable,axis=0)\n",
    "# data4 = data3.loc[:,keep3]\n",
    "# keep4 = data4.apply(dropNoISSP,axis=0)\n",
    "# data5 = data4.loc[:,keep4]\n",
    "# keep5 = data5.apply(dropUncodeable,axis=0)\n",
    "# data6 = data5.loc[:,keep5]\n",
    "# useCols = data5.columns.values\n",
    "\n",
    "# process the original dataset and get a much smaller one\n",
    "# chunkSize = 100000\n",
    "# data = pd.read_csv(file,nrows = chunkSize,usecols = useCols)\n",
    "# data = data.rename(renameColumns, axis='columns')\n",
    "# data.to_csv(fileLoc + 'gss_filter.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the smaller data\n",
    "data = pd.read_csv(fileLoc + 'gss_filter.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now summarize the column and delete those with only one value\n",
    "cts = data.apply(lambda x:len(x.value_counts()),axis=0)  # all columns have more than one values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the label is general happyness\n",
    "label_ind = np.where(data.columns.values == 'GENERAL HAPPINESS_labels')[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder,StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "ftypes = data.apply(lambda x: type(x.values[0]),axis = 0)  #all columns are numpy.float64\n",
    "onehotMask = [x == str for x in ftypes]\n",
    "onehotMask[label_ind] = False\n",
    "tmpData = data.loc[:,onehotMask]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## format for LGPR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorizeFeature(x):\n",
    "    idmap = {each:i for i,each in enumerate(set(x))}\n",
    "    if len(idmap) > 1:\n",
    "        return np.array([idmap[each] for each in x]).reshape(-1,1)\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "colnames = []\n",
    "tmpData_np = np.array(tmpData.values)\n",
    "cateRes = None\n",
    "for each in range(tmpData_np.shape[1]):\n",
    "    if cateRes is None:\n",
    "        r = categorizeFeature(tmpData_np[:,each])\n",
    "        if r is not None:\n",
    "            cateRes = r\n",
    "            colnames.append(tmpData.columns.values[each])\n",
    "    else:\n",
    "        r = categorizeFeature(tmpData_np[:,each])\n",
    "        if r is not None:\n",
    "            cateRes = np.concatenate([cateRes,r],axis=1)\n",
    "            colnames.append(tmpData.columns.values[each])\n",
    "colnames = np.array(colnames)            \n",
    "cateCols = np.arange(len(colnames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmpContData = data.loc[:,~np.array(onehotMask)].drop(['RESPONDNT ID NUMBER','GENERAL HAPPINESS_labels'],axis=1)\n",
    "stdModel = StandardScaler()\n",
    "stdRes = stdModel.fit_transform(np.array(tmpContData))\n",
    "# impute the missing values in the continuous feature\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "imp = IterativeImputer(max_iter=30, random_state=0)\n",
    "stdRes = imp.fit_transform(stdRes)\n",
    "colnames = np.concatenate([colnames,tmpContData.columns.values])\n",
    "contCols = np.arange(len(cateCols),len(cateCols)+len(tmpContData.columns.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = data['GENERAL HAPPINESS_labels']\n",
    "y = []\n",
    "for each in labels:\n",
    "#     if each == 'NOT TOO HAPPY':\n",
    "#         rating.append(1)\n",
    "    if each == 'PRETTY HAPPY' or each == 'VERY HAPPY':\n",
    "        y.append(1)\n",
    "    else:\n",
    "        y.append(0)\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "idCol = data['RESPONDNT ID NUMBER'].values\n",
    "oidCol = data['GSS YEAR FOR THIS RESPONDENT'].values\n",
    "X = np.concatenate([cateRes,stdRes],axis=1)\n",
    "\n",
    "def getLastOfSplit(x):\n",
    "    sp = x.split('_')\n",
    "    return sp[len(sp)-1]\n",
    "\n",
    "def filterLogic(x):\n",
    "    if x == 'IAP' or x == 'DK' or x == 'NONE':\n",
    "        return False\n",
    "    elif 'IAP' in x or 'ISSP' in x:\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "v = [getLastOfSplit(x) for x in colnames]\n",
    "v = [filterLogic(x) for x in v]\n",
    "X = X[:,v]\n",
    "colnames = colnames[v]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1500, 212)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# format a small dataset containing only several individuals\n",
    "from collections import Counter\n",
    "ct = Counter(idCol)\n",
    "top = 50\n",
    "targetIds = set([x[0] for x in ct.most_common()[:top]])\n",
    "mask = [x in targetIds for x in idCol]\n",
    "idCol = idCol[mask]\n",
    "oidCol = oidCol[mask]\n",
    "X = X[mask]\n",
    "y = y[mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## format for other algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "colnames = []\n",
    "onehotModel = OneHotEncoder()\n",
    "onehotRes = onehotModel.fit_transform(np.array(tmpData.values).astype(str))\n",
    "for i in range(len(onehotModel.categories_)):\n",
    "    colnames.extend([tmpData.columns.values[i]+'_'+str(x) for x in onehotModel.categories_[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GSS YEAR FOR THIS RESPONDENT</th>\n",
       "      <th>RESPONDNT ID NUMBER</th>\n",
       "      <th>LABOR FORCE STATUS_labels</th>\n",
       "      <th>R SELF-EMP OR WORKS FOR SOMEBODY_labels</th>\n",
       "      <th>MARITAL STATUS_labels</th>\n",
       "      <th>EVER BEEN DIVORCED OR SEPARATED_labels</th>\n",
       "      <th>SPOUSE LABOR FORCE STATUS_labels</th>\n",
       "      <th>SPOUSE SELF-EMP. OR WORKS FOR SOMEBODY_labels</th>\n",
       "      <th>FATHER SELF-EMP. OR WORKED FOR SOMEBODY_labels</th>\n",
       "      <th>RS HIGHEST DEGREE_labels</th>\n",
       "      <th>...</th>\n",
       "      <th>2ND MENTIONED COUNTRY OF SPOUSES ORIGIN_labels</th>\n",
       "      <th>3RD MENTIONED COUNTRY OF SPOUSES ORIGIN_labels</th>\n",
       "      <th>YEARS IN ARMED FORCES_labels</th>\n",
       "      <th>TAKE ACTIVE PART IN WORLD AFFAIRS_labels</th>\n",
       "      <th>REMAIN IN U.N. OR PULL OUT_labels</th>\n",
       "      <th>FEELINGS ABOUT COMMUNISM_labels</th>\n",
       "      <th>Weight deal with experimental randomization</th>\n",
       "      <th>SAMPLING FRAME AND METHOD_labels</th>\n",
       "      <th>WEIGHTS FOR BLACK OVERSAMPLES</th>\n",
       "      <th>Interviews Conducted in Spanish or English_labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1972.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>WORKING FULLTIME</td>\n",
       "      <td>SOMEONE ELSE</td>\n",
       "      <td>NEVER MARRIED</td>\n",
       "      <td>IAP</td>\n",
       "      <td>IAP</td>\n",
       "      <td>IAP</td>\n",
       "      <td>SOMEONE ELSE</td>\n",
       "      <td>BACHELOR</td>\n",
       "      <td>...</td>\n",
       "      <td>UNCODEABLE &amp; IAP</td>\n",
       "      <td>UNCODEABLE &amp; IAP</td>\n",
       "      <td>IAP</td>\n",
       "      <td>IAP</td>\n",
       "      <td>IAP</td>\n",
       "      <td>IAP</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1960 BQ</td>\n",
       "      <td>1.0</td>\n",
       "      <td>ENGLISH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1972.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>RETIRED</td>\n",
       "      <td>SOMEONE ELSE</td>\n",
       "      <td>MARRIED</td>\n",
       "      <td>NO</td>\n",
       "      <td>KEEPING HOUSE</td>\n",
       "      <td>IAP</td>\n",
       "      <td>SELF-EMPLOYED</td>\n",
       "      <td>LT HIGH SCHOOL</td>\n",
       "      <td>...</td>\n",
       "      <td>UNCODEABLE &amp; IAP</td>\n",
       "      <td>UNCODEABLE &amp; IAP</td>\n",
       "      <td>IAP</td>\n",
       "      <td>IAP</td>\n",
       "      <td>IAP</td>\n",
       "      <td>IAP</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1960 BQ</td>\n",
       "      <td>1.0</td>\n",
       "      <td>ENGLISH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1972.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>WORKING PARTTIME</td>\n",
       "      <td>SOMEONE ELSE</td>\n",
       "      <td>MARRIED</td>\n",
       "      <td>NO</td>\n",
       "      <td>WORKING FULLTIME</td>\n",
       "      <td>SOMEONE ELSE</td>\n",
       "      <td>SOMEONE ELSE</td>\n",
       "      <td>HIGH SCHOOL</td>\n",
       "      <td>...</td>\n",
       "      <td>UNCODEABLE &amp; IAP</td>\n",
       "      <td>UNCODEABLE &amp; IAP</td>\n",
       "      <td>IAP</td>\n",
       "      <td>IAP</td>\n",
       "      <td>IAP</td>\n",
       "      <td>IAP</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1960 BQ</td>\n",
       "      <td>1.0</td>\n",
       "      <td>ENGLISH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1972.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>WORKING FULLTIME</td>\n",
       "      <td>SOMEONE ELSE</td>\n",
       "      <td>MARRIED</td>\n",
       "      <td>NO</td>\n",
       "      <td>WORKING FULLTIME</td>\n",
       "      <td>SOMEONE ELSE</td>\n",
       "      <td>SOMEONE ELSE</td>\n",
       "      <td>BACHELOR</td>\n",
       "      <td>...</td>\n",
       "      <td>UNCODEABLE &amp; IAP</td>\n",
       "      <td>UNCODEABLE &amp; IAP</td>\n",
       "      <td>IAP</td>\n",
       "      <td>IAP</td>\n",
       "      <td>IAP</td>\n",
       "      <td>IAP</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1960 BQ</td>\n",
       "      <td>1.0</td>\n",
       "      <td>ENGLISH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1972.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>KEEPING HOUSE</td>\n",
       "      <td>SOMEONE ELSE</td>\n",
       "      <td>MARRIED</td>\n",
       "      <td>NO</td>\n",
       "      <td>TEMP NOT WORKING</td>\n",
       "      <td>SOMEONE ELSE</td>\n",
       "      <td>SOMEONE ELSE</td>\n",
       "      <td>HIGH SCHOOL</td>\n",
       "      <td>...</td>\n",
       "      <td>UNCODEABLE &amp; IAP</td>\n",
       "      <td>UNCODEABLE &amp; IAP</td>\n",
       "      <td>IAP</td>\n",
       "      <td>IAP</td>\n",
       "      <td>IAP</td>\n",
       "      <td>IAP</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1960 BQ</td>\n",
       "      <td>1.0</td>\n",
       "      <td>ENGLISH</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 214 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   GSS YEAR FOR THIS RESPONDENT  RESPONDNT ID NUMBER  \\\n",
       "0                        1972.0                  1.0   \n",
       "1                        1972.0                  2.0   \n",
       "2                        1972.0                  3.0   \n",
       "3                        1972.0                  4.0   \n",
       "4                        1972.0                  5.0   \n",
       "\n",
       "  LABOR FORCE STATUS_labels R SELF-EMP OR WORKS FOR SOMEBODY_labels  \\\n",
       "0          WORKING FULLTIME                            SOMEONE ELSE   \n",
       "1                   RETIRED                            SOMEONE ELSE   \n",
       "2          WORKING PARTTIME                            SOMEONE ELSE   \n",
       "3          WORKING FULLTIME                            SOMEONE ELSE   \n",
       "4             KEEPING HOUSE                            SOMEONE ELSE   \n",
       "\n",
       "  MARITAL STATUS_labels EVER BEEN DIVORCED OR SEPARATED_labels  \\\n",
       "0         NEVER MARRIED                                    IAP   \n",
       "1               MARRIED                                     NO   \n",
       "2               MARRIED                                     NO   \n",
       "3               MARRIED                                     NO   \n",
       "4               MARRIED                                     NO   \n",
       "\n",
       "  SPOUSE LABOR FORCE STATUS_labels  \\\n",
       "0                              IAP   \n",
       "1                    KEEPING HOUSE   \n",
       "2                 WORKING FULLTIME   \n",
       "3                 WORKING FULLTIME   \n",
       "4                 TEMP NOT WORKING   \n",
       "\n",
       "  SPOUSE SELF-EMP. OR WORKS FOR SOMEBODY_labels  \\\n",
       "0                                           IAP   \n",
       "1                                           IAP   \n",
       "2                                  SOMEONE ELSE   \n",
       "3                                  SOMEONE ELSE   \n",
       "4                                  SOMEONE ELSE   \n",
       "\n",
       "  FATHER SELF-EMP. OR WORKED FOR SOMEBODY_labels RS HIGHEST DEGREE_labels  \\\n",
       "0                                   SOMEONE ELSE                 BACHELOR   \n",
       "1                                  SELF-EMPLOYED           LT HIGH SCHOOL   \n",
       "2                                   SOMEONE ELSE              HIGH SCHOOL   \n",
       "3                                   SOMEONE ELSE                 BACHELOR   \n",
       "4                                   SOMEONE ELSE              HIGH SCHOOL   \n",
       "\n",
       "   ... 2ND MENTIONED COUNTRY OF SPOUSES ORIGIN_labels  \\\n",
       "0  ...                               UNCODEABLE & IAP   \n",
       "1  ...                               UNCODEABLE & IAP   \n",
       "2  ...                               UNCODEABLE & IAP   \n",
       "3  ...                               UNCODEABLE & IAP   \n",
       "4  ...                               UNCODEABLE & IAP   \n",
       "\n",
       "  3RD MENTIONED COUNTRY OF SPOUSES ORIGIN_labels YEARS IN ARMED FORCES_labels  \\\n",
       "0                               UNCODEABLE & IAP                          IAP   \n",
       "1                               UNCODEABLE & IAP                          IAP   \n",
       "2                               UNCODEABLE & IAP                          IAP   \n",
       "3                               UNCODEABLE & IAP                          IAP   \n",
       "4                               UNCODEABLE & IAP                          IAP   \n",
       "\n",
       "  TAKE ACTIVE PART IN WORLD AFFAIRS_labels REMAIN IN U.N. OR PULL OUT_labels  \\\n",
       "0                                      IAP                               IAP   \n",
       "1                                      IAP                               IAP   \n",
       "2                                      IAP                               IAP   \n",
       "3                                      IAP                               IAP   \n",
       "4                                      IAP                               IAP   \n",
       "\n",
       "  FEELINGS ABOUT COMMUNISM_labels Weight deal with experimental randomization  \\\n",
       "0                             IAP                                         1.0   \n",
       "1                             IAP                                         1.0   \n",
       "2                             IAP                                         1.0   \n",
       "3                             IAP                                         1.0   \n",
       "4                             IAP                                         1.0   \n",
       "\n",
       "  SAMPLING FRAME AND METHOD_labels WEIGHTS FOR BLACK OVERSAMPLES  \\\n",
       "0                          1960 BQ                           1.0   \n",
       "1                          1960 BQ                           1.0   \n",
       "2                          1960 BQ                           1.0   \n",
       "3                          1960 BQ                           1.0   \n",
       "4                          1960 BQ                           1.0   \n",
       "\n",
       "  Interviews Conducted in Spanish or English_labels  \n",
       "0                                           ENGLISH  \n",
       "1                                           ENGLISH  \n",
       "2                                           ENGLISH  \n",
       "3                                           ENGLISH  \n",
       "4                                           ENGLISH  \n",
       "\n",
       "[5 rows x 214 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmpContData = data.loc[:,~np.array(onehotMask)].drop(['RESPONDNT ID NUMBER','GENERAL HAPPINESS_labels'],axis=1)\n",
    "stdModel = StandardScaler()\n",
    "stdRes = stdModel.fit_transform(np.array(tmpContData))\n",
    "# impute the missing values in the continuous feature\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "imp = IterativeImputer(max_iter=30, random_state=0)\n",
    "stdRes = imp.fit_transform(stdRes)\n",
    "colnames = np.concatenate([colnames,tmpContData.columns.values])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = data['GENERAL HAPPINESS_labels']\n",
    "y = []\n",
    "for each in labels:\n",
    "#     if each == 'NOT TOO HAPPY':\n",
    "#         rating.append(1)\n",
    "    if each == 'PRETTY HAPPY' or each == 'VERY HAPPY':\n",
    "        y.append(1)\n",
    "    else:\n",
    "        y.append(0)\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "idCol = data['RESPONDNT ID NUMBER'].values\n",
    "oidCol = data['GSS YEAR FOR THIS RESPONDENT'].values\n",
    "X = np.concatenate([onehotRes.toarray(),stdRes],axis=1)\n",
    "\n",
    "def getLastOfSplit(x):\n",
    "    sp = x.split('_')\n",
    "    return sp[len(sp)-1]\n",
    "\n",
    "def filterLogic(x):\n",
    "    if x == 'IAP' or x == 'DK' or x == 'NONE':\n",
    "        return False\n",
    "    elif 'IAP' in x or 'ISSP' in x:\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "v = [getLastOfSplit(x) for x in colnames]\n",
    "v = [filterLogic(x) for x in v]\n",
    "X = X[:,v]\n",
    "colnames = colnames[v]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(59599, 1392)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# format a small dataset containing only several individuals\n",
    "from collections import Counter\n",
    "ct = Counter(idCol)\n",
    "top = 50\n",
    "targetIds = set([x[0] for x in ct.most_common()[:top]])\n",
    "mask = [x in targetIds for x in idCol]\n",
    "idCol = idCol[mask]\n",
    "oidCol = oidCol[mask]\n",
    "X = X[mask]\n",
    "y = y[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def splitTrainTest(ids, time, prop=.7, seed = 19):\n",
    "    np.random.seed(seed)\n",
    "    mask = np.array([np.random.uniform() < prop for x in ids])\n",
    "    trainIdx, trainTime = ids[mask], time[mask]\n",
    "    testIdx,testTime = ids[~mask],time[~mask]\n",
    "    trainDict = defaultdict(list)\n",
    "    testDict = defaultdict(list)\n",
    "    \n",
    "    for i,m in enumerate(mask):\n",
    "        if m:\n",
    "            trainDict[ids[i]].append((time[i],i))\n",
    "        else:\n",
    "            testDict[ids[i]].append((time[i],i))\n",
    "    for k,v in trainDict.items():\n",
    "        trainV = [x[0] for x in v]\n",
    "        trainVid = [x[1] for x in v]\n",
    "        tv = testDict.get(k,None)\n",
    "        if tv is not None:\n",
    "            testV = [x[0] for x in tv]\n",
    "            testVid = [x[1] for x in tv]\n",
    "            maxId = np.argmax(trainV)\n",
    "            minId = np.argmin(testV)\n",
    "            while trainV[maxId] > testV[minId]:\n",
    "                tmp = trainV[maxId]\n",
    "                trainV[maxId] = testV[minId]\n",
    "                testV[minId] = tmp\n",
    "                tmp = trainVid[maxId]\n",
    "                trainVid[maxId] = testVid[minId]\n",
    "                testVid[minId] = tmp\n",
    "                maxId = np.argmax(trainV)\n",
    "                minId = np.argmin(testV)\n",
    "            trainDict[k] = [(x,y) for x,y in zip(trainV,trainVid)]\n",
    "            testDict[k] = [(x,y) for x,y in zip(testV,testVid)]\n",
    "    train = []\n",
    "    test = []\n",
    "    for k,v in trainDict.items():\n",
    "        train.extend([x[1] for x in v])\n",
    "    for k,v in testDict.items():\n",
    "        test.extend([x[1] for x in v])\n",
    "    return train, test\n",
    "\n",
    "def getIndvFixFeature(ids,x):\n",
    "    dt = defaultdict(list)\n",
    "    for i,k in enumerate(ids):\n",
    "        dt[k].append(x[i])\n",
    "    noChange = np.repeat(True,x.shape[1])\n",
    "    for k,v in dt.items():\n",
    "        v = np.array(v)\n",
    "        for i in range(v.shape[1]):\n",
    "            if np.sum(v[:,i] - v[0,i]) != 0:\n",
    "                noChange[i] = False\n",
    "    return noChange\n",
    "\n",
    "from scipy import io\n",
    "def generate(seed = 19,density = 0.7,name = 'gss'):\n",
    "    trainIdx, testIdx = splitTrainTest(idCol, X[:,np.where(colnames == 'GSS YEAR FOR THIS RESPONDENT')[0]].reshape(-1),density,seed)\n",
    "    if name == 'gssLGPR':\n",
    "        io.savemat(f'../gssLGPR_{seed}',{'trainId':idCol[trainIdx],'trainOid':oidCol[trainIdx],'trainX':X[trainIdx],'trainY':y[trainIdx],\n",
    "                                  'testId':idCol[testIdx],'testOid':oidCol[testIdx],'testX':X[testIdx],'testY':y[testIdx],'colname':colnames,\n",
    "                                        'cateCols':cateCols, 'contCols':contCols})\n",
    "    else:\n",
    "        io.savemat(f'../gss_{seed}',{'trainId':idCol[trainIdx],'trainOid':oidCol[trainIdx],'trainX':X[trainIdx],'trainY':y[trainIdx],\n",
    "                                  'testId':idCol[testIdx],'testOid':oidCol[testIdx],'testX':X[testIdx],'testY':y[testIdx],'colname':colnames})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate(seed = 14,name='gssLGPR')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
