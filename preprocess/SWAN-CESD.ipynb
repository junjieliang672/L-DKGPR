{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SWAN data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The official website of this data:\n",
    "https://www.icpsr.umich.edu/icpsrweb/ICPSR/series/00253\n",
    "\n",
    "related paper: Quintana, F. A., Johnson, W. O., Waetjen, L. E., & B. Gold, E. (2016). Bayesian nonparametric longitudinal data analysis. Journal of the American Statistical Association, 111(515), 1168-1181.\n",
    "\n",
    "Preprocessing:\n",
    "There are 11 separate files for this dataset, I combine all of them to a single large file.\n",
    "\n",
    "1. There are three types of features, numerical, categorical and date. All features related to date are removed directly.\n",
    "1. Categorical features are expended using onehot encoding. The nan values for the categorical features are viewed as unique features, which are also removed.\n",
    "1. The nan values for numerical feature are imputed using regression.\n",
    "1. The observation is defined asthe age of the subject to capture the belief that, the age of a subject is another main factors to the outcome.\n",
    "\n",
    "Statistics:\n",
    "\n",
    "records: 28489\n",
    "\n",
    "features: 139 (including subject id, observation id and outcome)\n",
    "\n",
    "subjects: 3302\n",
    "\n",
    "observations: 11 (ranging from 1994 - 2008) (age of subject: 42 - 63)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# driveLoc = \"F:/onedrive\"\n",
    "# driveLoc = \"/Users/jul672/Desktop/OneDrive\"\n",
    "driveLoc = \"C:/Users/jokit/OneDrive\"\n",
    "fileLoc = driveLoc+'/phd projects/Study of Women\\'s Health Across the Nation (SWAN)/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# heads = None\n",
    "# for i in range(11):\n",
    "#     file = fileLoc + 'wave' + str(i) + '.csv'\n",
    "#     if heads is None:\n",
    "#         heads = pd.read_csv(file,nrows=1).columns.values\n",
    "#         heads[2:] = [x[:-1] for x in heads[2:]]\n",
    "#     else:\n",
    "#         tmp = pd.read_csv(file,nrows=1).columns.values\n",
    "#         if i < 10:\n",
    "#             tmp[2:] = [x[:-1] for x in tmp[2:]]\n",
    "#         else:\n",
    "#             tmp[2:] = [x[:-2] for x in tmp[2:]]\n",
    "#         mask = [x in tmp for x in heads]\n",
    "#         heads = heads[mask]\n",
    "# legalHeads = heads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# legalHeads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "legalHeads = ['SWANID', 'VISIT', 'AGE', 'PREGNAN', 'ALCHL24','RACE',\n",
    "       'EATDRIN', 'STRTPER', 'BLDRWAT', 'BLDDRAW', 'THYROID', 'STROKE',\n",
    "       'HBCHOLE', 'MIGRAIN', 'OSTEOAR', 'ANEMIA', 'BOTHER', 'APPETIT',\n",
    "       'BLUES', 'GOOD', 'KEEPMIN', 'DEPRESS', 'EFFORT', 'HOPEFUL',\n",
    "       'FAILURE', 'FEARFUL', 'RESTLES', 'HAPPY', 'TALKLES', 'LONELY',\n",
    "       'UNFRNDL', 'ENJOY', 'CRYING', 'SAD', 'DISLIKE', 'GETGOIN', 'JOB',\n",
    "       'HOSPSTA', 'MDTALK', 'PAPSMEA', 'BRSTEXA', 'MAMOGRA',\n",
    "       'SMOKERE', 'AVCIGDA', 'STIFF', 'COLDSWE', 'NITESWE', 'VAGINDR',\n",
    "       'FEELBLU', 'DIZZY', 'IRRITAB', 'NRVOUS', 'FORGET', 'MOODCHG',\n",
    "       'HARTRAC', 'FEARFULA', 'HDACHE', 'HOTFLAS', 'TRBLSLE', 'WAKEUP',\n",
    "       'WAKEARL', 'DANDC', 'UTERPRO', 'INCOME', 'STARTNE', 'WORKTRB',\n",
    "       'QUITJOB', 'WORKLOA', 'PRTUNEM', 'MONEYPR', 'WORSREL', 'RELATEN',\n",
    "       'SERIPRO', 'CHILDMO', 'RESPCAR', 'LEGALPR', 'SELFVIO', 'MAJEVEN',\n",
    "       'PULSE', 'SYSBP1', 'DIABP1', 'SYSBP2', 'DIABP2',\n",
    "       'HEIGHT', 'HTMETHO', 'WEIGHT', 'SCALE', 'WAIST', 'WASTMEA', 'HIP',\n",
    "       'HIPMEAS', 'BMI', 'DHAS', 'FSH', 'SHBG', 'T',\n",
    "       'E2AVE', 'FLGCV', 'FLGDIF', 'SPSCTIM', 'SPSCMOD',\n",
    "       'HPSCTIM', 'HPSCMOD', 'SPBMDT', 'HPBMDT', 'BMDFLG',\n",
    "       'STATUS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "needDummy = ['PREGNAN', 'ALCHL24','RACE',\n",
    "       'EATDRIN', 'STRTPER', 'BLDRWAT', 'BLDDRAW', 'THYROID', 'STROKE',\n",
    "       'HBCHOLE', 'MIGRAIN', 'OSTEOAR', 'ANEMIA', 'BOTHER', 'APPETIT',\n",
    "       'BLUES', 'GOOD', 'KEEPMIN', 'DEPRESS', 'EFFORT', 'HOPEFUL',\n",
    "       'FAILURE', 'FEARFUL', 'RESTLES', 'HAPPY', 'TALKLES', 'LONELY',\n",
    "       'UNFRNDL', 'ENJOY', 'CRYING', 'SAD', 'DISLIKE', 'GETGOIN', 'JOB',\n",
    "       'PAPSMEA', 'BRSTEXA', 'MAMOGRA',\n",
    "       'SMOKERE', 'AVCIGDA', 'STIFF', 'COLDSWE', 'NITESWE', 'VAGINDR',\n",
    "       'FEELBLU', 'DIZZY', 'IRRITAB', 'NRVOUS', 'FORGET', 'MOODCHG',\n",
    "       'HARTRAC', 'FEARFULA', 'HDACHE', 'HOTFLAS', 'TRBLSLE', 'WAKEUP',\n",
    "       'WAKEARL', 'DANDC', 'UTERPRO', 'INCOME', 'STARTNE', 'WORKTRB',\n",
    "       'QUITJOB', 'WORKLOA', 'PRTUNEM', 'MONEYPR', 'WORSREL', 'RELATEN',\n",
    "       'SERIPRO', 'CHILDMO', 'RESPCAR', 'LEGALPR', 'SELFVIO', 'MAJEVEN',\n",
    "       'HTMETHO', 'SCALE', 'WASTMEA',\n",
    "       'HIPMEAS',\n",
    "       'FLGCV', 'FLGDIF', 'SPSCMOD',\n",
    "       'HPSCMOD','BMDFLG',\n",
    "       'STATUS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(fileLoc + 'full.csv',usecols=legalHeads,delimiter=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute CES-D   https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3197240/\n",
    "bad = ['BOTHER','APPETIT','BLUES','DEPRESS','FAILURE','FEARFUL','RESTLES','TALKLES','LONELY','UNFRNDL','CRYING','SAD','DISLIKE','GETGOIN']\n",
    "good = ['GOOD','EFFORT','HOPEFUL','HAPPY','ENJOY','KEEPMIN']\n",
    "\n",
    "def formatEntry(x):\n",
    "    v1 = str(x).lower()\n",
    "    v2 = v1.split(':')\n",
    "    if len(v2) > 1:\n",
    "        return v2[1].strip()\n",
    "    else:\n",
    "        return v1\n",
    "\n",
    "def getCesdScoreForColumn(col):\n",
    "    tmp = data[col].values\n",
    "    ans = np.array(list(map(formatEntry,tmp)))\n",
    "    s = []\n",
    "    if col in bad:\n",
    "        for x in ans:\n",
    "            if x == 'rarely/none of the time (< 1 day)':\n",
    "                s.append(0)\n",
    "            elif x == 'some/a little of the time (1-2 days)':\n",
    "                s.append(1)\n",
    "            elif x == 'occasionally/mod amt of the time (3-4 days)':\n",
    "                s.append(2)\n",
    "            elif x == 'most/all of the time (5-7 days)':\n",
    "                s.append(3)\n",
    "            else:\n",
    "                s.append(0)\n",
    "    else:\n",
    "        for x in ans:\n",
    "            if x == 'rarely/none of the time (< 1 day)':\n",
    "                s.append(3)\n",
    "            elif x == 'some/a little of the time (1-2 days)':\n",
    "                s.append(2)\n",
    "            elif x == 'occasionally/mod amt of the time (3-4 days)':\n",
    "                s.append(1)\n",
    "            elif x == 'most/all of the time (5-7 days)':\n",
    "                s.append(0)\n",
    "            else:\n",
    "                s.append(0)\n",
    "    return np.array(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad = ['BOTHER','APPETIT','BLUES','DEPRESS','FAILURE','FEARFUL','RESTLES','TALKLES','LONELY','UNFRNDL','CRYING','SAD','DISLIKE','GETGOIN']\n",
    "good = ['GOOD','EFFORT','HOPEFUL','HAPPY','ENJOY','KEEPMIN']\n",
    "cesd = None\n",
    "for col in bad:\n",
    "    if cesd is None:\n",
    "        cesd = getCesdScoreForColumn(col)\n",
    "    else:\n",
    "        cesd += getCesdScoreForColumn(col)\n",
    "for col in good:\n",
    "    cesd += getCesdScoreForColumn(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "legalHeads = ['SWANID', 'VISIT', 'AGE', 'PREGNAN', 'ALCHL24','RACE',\n",
    "       'EATDRIN', 'STRTPER', 'THYROID', 'STROKE',\n",
    "       'MIGRAIN', 'OSTEOAR', 'ANEMIA','JOB',\n",
    "       'HOSPSTA', 'MDTALK', \n",
    "       'SMOKERE', 'STIFF', 'COLDSWE', 'NITESWE', \n",
    "       'DIZZY', 'IRRITAB', 'NRVOUS', 'FORGET', 'MOODCHG',\n",
    "       'HARTRAC', 'HDACHE', 'HOTFLAS', 'TRBLSLE', 'WAKEUP',\n",
    "       'WAKEARL', 'DANDC', 'UTERPRO', 'INCOME', 'STARTNE', 'WORKTRB',\n",
    "       'QUITJOB', 'WORKLOA', 'PRTUNEM', 'MONEYPR', 'WORSREL', 'RELATEN',\n",
    "       'SERIPRO', 'CHILDMO', 'RESPCAR', 'LEGALPR', 'SELFVIO', 'MAJEVEN',\n",
    "       'HEIGHT','WEIGHT', 'WAIST', 'HIP',\n",
    "       'BMI', 'DHAS', 'FSH', 'SHBG', 'T',\n",
    "       'E2AVE','SPBMDT', 'HPBMDT','STATUS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "legalHeadsRename = np.array(['SWANID', 'VISIT', 'AGE', 'Pregnant', 'Alcohol24Hrs','Race',\n",
    "       'EatOrDrink12Hrs', 'PeriodPastWk', 'ThyroidMed', 'Stroke',\n",
    "       'Migraines', 'Arthritis', 'Anemia','WorkPast2Wks',\n",
    "       'HospitalStayPastYear', 'TalkLastYr', \n",
    "       'Smoke', 'StiffnessPast2Wks', 'ColdSweatPast2Wks', 'NightSweatPast2Wks', \n",
    "       'DizzyPast2Wks', 'IrritablePast2Wks', 'NervousPast2Wks', 'ForgetfulnessPast2Wks', 'MoodChangePast2Wks',\n",
    "       'HeartRacingPast2Wks', 'HeadachePast2Wks', 'HotFlashesPast2Wks', 'TroubleSleepPast2Wks', 'WakeupSeveralTimesPast2Wks',\n",
    "       'WakeupEarlyPast2Wks', 'HadD&C', 'HadUterineProcedures', 'Income', 'StartNewJobUpset', 'WorkProblemUpset',\n",
    "       'QuitJobUpset', 'IncreaseWorkLoadUpset', 'PartnerUnempUpset', 'MoneyProblemUpset', 'WorsenRelationUpset', 'EndedRelationUpset',\n",
    "       'FamilyProblemUpset', 'ChildMovedUpset', 'ResponsibilityForCareUpset', 'LegalProblemUpset', 'ViolentEventUpset', 'OtherEventUpset',\n",
    "       'Height', 'Weight', 'Waist', 'Hip',\n",
    "       'BMI', 'DHAS', 'FSH', 'SHBG', 'Testosterone',\n",
    "       'Estradiol','SplineBoneDensity', 'HipBoneDensity','STATUS'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "needDummy = [\n",
    "    'Pregnant', 'Alcohol24Hrs','Race',\n",
    "       'EatOrDrink12Hrs', 'PeriodPastWk', 'ThyroidMed', 'Stroke',\n",
    "       'Migraines', 'Arthritis', 'Anemia','WorkPast2Wks',\n",
    "       'HospitalStayPastYear', 'TalkLastYr', \n",
    "       'Smoke', 'StiffnessPast2Wks', 'ColdSweatPast2Wks', 'NightSweatPast2Wks', \n",
    "       'DizzyPast2Wks', 'IrritablePast2Wks', 'NervousPast2Wks', 'ForgetfulnessPast2Wks', 'MoodChangePast2Wks',\n",
    "       'HeartRacingPast2Wks', 'HeadachePast2Wks', 'HotFlashesPast2Wks', 'TroubleSleepPast2Wks', 'WakeupSeveralTimesPast2Wks',\n",
    "       'WakeupEarlyPast2Wks', 'HadD&C', 'HadUterineProcedures', 'Income', 'StartNewJobUpset', 'WorkProblemUpset',\n",
    "       'QuitJobUpset', 'IncreaseWorkLoadUpset', 'PartnerUnempUpset', 'MoneyProblemUpset', 'WorsenRelationUpset', 'EndedRelationUpset',\n",
    "       'FamilyProblemUpset', 'ChildMovedUpset', 'ResponsibilityForCareUpset', 'LegalProblemUpset', 'ViolentEventUpset', 'OtherEventUpset',\n",
    "       'STATUS'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(fileLoc + 'full.csv',usecols=legalHeads,delimiter=';')\n",
    "data = data.rename({legalHeads[x]:legalHeadsRename[x] for x in range(len(legalHeads))},axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change the name of the columns\n",
    "# change some of the continuous factors to discrete but more meaningful values\n",
    "talk = data.TalkLastYr.values\n",
    "def TalkMuch(x):\n",
    "    if x > 10:\n",
    "        return 'talk a lot (>10)'\n",
    "    elif x >= 1 and x <= 10:\n",
    "        return 'few (1 to 10)'\n",
    "    elif x == 0:\n",
    "        return 'never (0)'\n",
    "    else:\n",
    "        return 'nan'\n",
    "talkDis = [TalkMuch(x) for x in talk]\n",
    "data['TalkLastYr'] = talkDis\n",
    "\n",
    "# hostpital stay\n",
    "hpsStay = data.HospitalStayPastYear.values\n",
    "def HospStay(x):\n",
    "    if x == 0:\n",
    "        return 'no'\n",
    "    elif x > 0:\n",
    "        return 'yes'\n",
    "    else:\n",
    "        return 'nan'\n",
    "hpsStayDis = [HospStay(x) for x in hpsStay]\n",
    "data['HospitalStayPastYear'] = hpsStayDis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reformat the income\n",
    "def incomeReformat(x):\n",
    "    newv = []\n",
    "    for each in x:\n",
    "        sp = each.split('_')\n",
    "        last = sp[len(sp) - 1]\n",
    "        if last == 'less than $19,999':\n",
    "            newv.append('very low (<20k)')\n",
    "        elif last == '$20,000 to $49,999' or last == '$50,000 to $99,999':\n",
    "            newv.append('medium (20k to 100k)')\n",
    "        elif last == '$100,000 or more':\n",
    "            newv.append('high (>100k)')\n",
    "        else:\n",
    "            newv.append('nan')\n",
    "    return newv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change the values of some discrete variables\n",
    "def cutDownValues(x):\n",
    "    newv = []\n",
    "    for each in x:\n",
    "        sp = each.split('_')\n",
    "        last = sp[len(sp) - 1]\n",
    "        if last == 'every day' or last == '9-13 days':\n",
    "            newv.append('a lot (>8)')\n",
    "        elif last == 'not at all':\n",
    "            newv.append('never')\n",
    "        elif last == '1-5 days' or last == '6-8 days':\n",
    "            newv.append('some (1 to 8)')\n",
    "        else:\n",
    "            newv.append('nan')\n",
    "    return newv\n",
    "            \n",
    "def upsettingCutDown(x):\n",
    "    newv = []\n",
    "    for each in x:\n",
    "        sp = each.split('_')\n",
    "        last = sp[len(sp) - 1]\n",
    "        if last == 'yes, very upsetting & still upsetting' or last == 'yes, very upsetting' or last == 'yes, somewhat upsetting':\n",
    "            newv.append('yes, upset')\n",
    "        elif last == 'yes, not at all upsetting':\n",
    "            newv.append('yes, but not upset')\n",
    "        elif last == 'no':\n",
    "            newv.append('no')\n",
    "        else:\n",
    "            newv.append('nan')\n",
    "    return newv\n",
    "featureNeedCutDown = ['StiffnessPast2Wks','ColdSweatPast2Wks', 'NightSweatPast2Wks', \n",
    "       'DizzyPast2Wks', 'IrritablePast2Wks', 'NervousPast2Wks', 'ForgetfulnessPast2Wks', 'MoodChangePast2Wks',\n",
    "       'HeartRacingPast2Wks', 'HeadachePast2Wks', 'HotFlashesPast2Wks', 'TroubleSleepPast2Wks', 'WakeupSeveralTimesPast2Wks',\n",
    "       'WakeupEarlyPast2Wks',]\n",
    "upsetFeatures = ['StartNewJobUpset', 'WorkProblemUpset',\n",
    "       'QuitJobUpset', 'IncreaseWorkLoadUpset', 'PartnerUnempUpset', 'MoneyProblemUpset', 'WorsenRelationUpset', 'EndedRelationUpset',\n",
    "       'FamilyProblemUpset', 'ChildMovedUpset', 'ResponsibilityForCareUpset', 'LegalProblemUpset', 'ViolentEventUpset', 'OtherEventUpset']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "observationCol = 'AGE'\n",
    "tmp = pd.DataFrame()\n",
    "tmpData = data[needDummy]\n",
    "for i in tmpData:\n",
    "    cols = tmpData[i].values\n",
    "    tmp[i] = list(map(formatEntry,cols))\n",
    "tmpData = tmp\n",
    "\n",
    "for each in featureNeedCutDown:\n",
    "    tmpData[each] = cutDownValues(tmpData[each].values)\n",
    "for each in upsetFeatures:\n",
    "    tmpData[each] = upsettingCutDown(tmpData[each].values)\n",
    "tmpData['Income'] = incomeReformat(tmpData['Income'].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## format for LGPR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder,StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorizeFeature(x):\n",
    "    idmap = {each:i for i,each in enumerate(set(x))}\n",
    "    if len(idmap) > 1:\n",
    "        return np.array([idmap[each] for each in x]).reshape(-1,1)\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "colnames = []\n",
    "tmpData_np = np.array(tmpData.values)\n",
    "cateRes = None\n",
    "for each in range(tmpData_np.shape[1]):\n",
    "    if cateRes is None:\n",
    "        r = categorizeFeature(tmpData_np[:,each])\n",
    "        if r is not None:\n",
    "            cateRes = r\n",
    "            colnames.append(tmpData.columns.values[each])\n",
    "    else:\n",
    "        r = categorizeFeature(tmpData_np[:,each])\n",
    "        if r is not None:\n",
    "            cateRes = np.concatenate([cateRes,r],axis=1)\n",
    "            colnames.append(tmpData.columns.values[each])\n",
    "colnames = np.array(colnames)            \n",
    "cateCols = np.arange(len(colnames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmpContData = data.drop(needDummy,axis=1).drop(['VISIT','SWANID'],axis=1)\n",
    "stdModel = StandardScaler()\n",
    "stdRes = stdModel.fit_transform(np.array(tmpContData))\n",
    "# impute the missing values in the continuous feature\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "imp = IterativeImputer(max_iter=50, random_state=0)\n",
    "stdRes = imp.fit_transform(stdRes)\n",
    "colnames = np.concatenate([colnames,tmpContData.columns.values])\n",
    "contCols = np.arange(len(cateCols),len(cateCols)+len(tmpContData.columns.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "idCol = data['SWANID'].values\n",
    "oidCol = data[observationCol].values\n",
    "X = np.concatenate([cateRes,stdRes],axis=1)\n",
    "y = cesd - 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_remove = np.isnan(oidCol)\n",
    "idCol = idCol[~mask_remove]\n",
    "oidCol = oidCol[~mask_remove]\n",
    "X = X[~mask_remove]\n",
    "y = y[~mask_remove]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# format a small dataset containing only several individuals\n",
    "from collections import Counter\n",
    "ct = Counter(idCol)\n",
    "top = 50\n",
    "targetIds = set([x[0] for x in ct.most_common()[:top]])\n",
    "mask = [x in targetIds for x in idCol]\n",
    "idCol = idCol[mask]\n",
    "oidCol = oidCol[mask]\n",
    "X = X[mask]\n",
    "y = y[mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## format for other algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "colnames = []\n",
    "onehotModel = OneHotEncoder()\n",
    "onehotRes = onehotModel.fit_transform(np.array(tmpData.values))\n",
    "for i in range(len(onehotModel.categories_)):\n",
    "    colnames.extend([tmpData.columns.values[i]+'_'+str(x) for x in onehotModel.categories_[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmpContData = data.drop(needDummy,axis=1).drop(['VISIT','SWANID'],axis=1)\n",
    "stdModel = StandardScaler()\n",
    "stdRes = stdModel.fit_transform(np.array(tmpContData))\n",
    "# impute the missing values in the continuous feature\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "imp = IterativeImputer(max_iter=50, random_state=0)\n",
    "stdRes = imp.fit_transform(stdRes)\n",
    "colnames = np.concatenate([colnames,tmpContData.columns.values])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "idCol = data['SWANID'].values\n",
    "oidCol = data[observationCol].values\n",
    "X = np.concatenate([onehotRes.toarray(),stdRes],axis=1)\n",
    "y = cesd - 15\n",
    "v = [not x.endswith('nan') for x in colnames]\n",
    "X = X[:,v]\n",
    "colnames = colnames[v]\n",
    "\n",
    "mask_remove = np.isnan(oidCol)\n",
    "idCol = idCol[~mask_remove]\n",
    "oidCol = oidCol[~mask_remove]\n",
    "X = X[~mask_remove]\n",
    "y = y[~mask_remove]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3300"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(idCol))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# format a small dataset containing only several individuals\n",
    "from collections import Counter\n",
    "ct = Counter(idCol)\n",
    "top = 50\n",
    "targetIds = set([x[0] for x in ct.most_common()[:top]])\n",
    "mask = [x in targetIds for x in idCol]\n",
    "idCol = idCol[mask]\n",
    "oidCol = oidCol[mask]\n",
    "X = X[mask]\n",
    "y = y[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def splitTrainTest(ids, time, prop=.7, seed = 19):\n",
    "    np.random.seed(seed)\n",
    "    mask = np.array([np.random.uniform() < prop for x in ids])\n",
    "    trainIdx, trainTime = ids[mask], time[mask]\n",
    "    testIdx,testTime = ids[~mask],time[~mask]\n",
    "    trainDict = defaultdict(list)\n",
    "    testDict = defaultdict(list)\n",
    "    \n",
    "    for i,m in enumerate(mask):\n",
    "        if m:\n",
    "            trainDict[ids[i]].append((time[i],i))\n",
    "        else:\n",
    "            testDict[ids[i]].append((time[i],i))\n",
    "    for k,v in trainDict.items():\n",
    "        trainV = [x[0] for x in v]\n",
    "        trainVid = [x[1] for x in v]\n",
    "        tv = testDict.get(k,None)\n",
    "        if tv is not None:\n",
    "            testV = [x[0] for x in tv]\n",
    "            testVid = [x[1] for x in tv]\n",
    "            maxId = np.argmax(trainV)\n",
    "            minId = np.argmin(testV)\n",
    "            while trainV[maxId] > testV[minId]:\n",
    "                tmp = trainV[maxId]\n",
    "                trainV[maxId] = testV[minId]\n",
    "                testV[minId] = tmp\n",
    "                tmp = trainVid[maxId]\n",
    "                trainVid[maxId] = testVid[minId]\n",
    "                testVid[minId] = tmp\n",
    "                maxId = np.argmax(trainV)\n",
    "                minId = np.argmin(testV)\n",
    "            trainDict[k] = [(x,y) for x,y in zip(trainV,trainVid)]\n",
    "            testDict[k] = [(x,y) for x,y in zip(testV,testVid)]\n",
    "    train = []\n",
    "    test = []\n",
    "    for k,v in trainDict.items():\n",
    "        train.extend([x[1] for x in v])\n",
    "    for k,v in testDict.items():\n",
    "        test.extend([x[1] for x in v])\n",
    "    return train, test\n",
    "\n",
    "def getIndvFixFeature(ids,x):\n",
    "    dt = defaultdict(list)\n",
    "    for i,k in enumerate(ids):\n",
    "        dt[k].append(x[i])\n",
    "    noChange = np.repeat(True,x.shape[1])\n",
    "    for k,v in dt.items():\n",
    "        v = np.array(v)\n",
    "        for i in range(v.shape[1]):\n",
    "            if np.sum(v[:,i] - v[0,i]) != 0:\n",
    "                noChange[i] = False\n",
    "    return noChange\n",
    "\n",
    "from scipy import io\n",
    "def generate(seed = 19,density = 0.7,name='swan'):\n",
    "    trainIdx, testIdx = splitTrainTest(idCol, X[:,np.where(colnames == 'AGE')[0]].reshape(-1),density,seed)\n",
    "#     noChange = getIndvFixFeature(idCol,X)\n",
    "#     tmp_idx = np.arange(X.shape[1])[~noChange]\n",
    "    if name == 'swanLGPR':\n",
    "        io.savemat(f'../{name}_{seed}',{'trainId':idCol[trainIdx],'trainOid':oidCol[trainIdx],'trainX':X[trainIdx],'trainY':y[trainIdx],\n",
    "                                  'testId':idCol[testIdx],'testOid':oidCol[testIdx],'testX':X[testIdx],'testY':y[testIdx],'colname':colnames,\n",
    "                                  'cateCols':cateCols,'contCols':contCols})\n",
    "    else:\n",
    "        io.savemat(f'../{name}_{seed}',{'trainId':idCol[trainIdx],'trainOid':oidCol[trainIdx],'trainX':X[trainIdx],'trainY':y[trainIdx],\n",
    "                                  'testId':idCol[testIdx],'testOid':oidCol[testIdx],'testX':X[testIdx],'testY':y[testIdx],'colname':colnames})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate(seed = 2)\n",
    "generate(seed = 14,name='swan')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
