{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jokit\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3049: DtypeWarning: Columns (471,473,474,487,488,489,490,491,492,493,494,495,496,497,498,499,500,501,502,503,504,505,506,507,508,509,510,511,512,513,514,515,516,517,518,519,520,521,522,523,524,525,526,527,528,529,530,531,532,533,534,535,536,537,538,539,540,541,542,543,544,545,546,547,548,549,550,551,552,553,554,555,556,557,558,559,560,561,562,563,569,570,572,573,574,575,576,577,578,579,580,581,582,583,584,585,586,587,588,589,590,591,592,593,594,595,596,597,599,601,606,607,608,609,610,611,612,613,614,615,616,617,618,619,620,621,624,625,626,627,628,629,630,631,632,633,634,636,637,638,639,640,641,642,643,644,645,646,647,648,649,650,651,652,653,654,655,656,657,658,659,660,661,663,664,665,666,667,668,669,670,671,672,673,674,675,676,677,678,679,680,681,682,683,684,685,686,687,688,689,690,691,692,693,694,695,696,697,698,699,700,701,702,703,704,705,706,707,708,709,710,711,712,713,714,715,716,717,718,719,720,721,722,723,724,725,726,727,728,729,730,731,732,733,734,735,736,737,738,739,745,746,748,749,750,751,752,753,754,755,756,757,758,759,760,761,762,763,764,765,766,767,770,771,776,777,778,779,780,781,782,783,784,785,786,787,788,789,790,791,794,795,797,798,799,800,801,802,803,804,806,807,808,809,810,811,812,813,814,815,816,817,818,819,820,821,822,823,824,825,826,827,828,829,830,831) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "# onedrive = 'F:/onedrive/'\n",
    "onedrive = \"C:/Users/jokit/OneDrive/\"\n",
    "path = f'{onedrive}Phd workshop/fmri/tadpole_challenge/'\n",
    "data = pd.read_csv(f'{path}TADPOLE_D1_D2.csv')\n",
    "D3 = pd.read_csv(f'{path}TADPOLE_D3.csv')\n",
    "v1 = data['D1'].values\n",
    "v2 = data['D2'].values\n",
    "D1 = data.loc[v1 == 1,:]\n",
    "D2 = data.loc[v2 == 1,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jokit\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\jokit\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "cols = D3.columns.values\n",
    "subD1 = D1[cols]\n",
    "subD1['D'] = np.repeat('D1',len(subD1))\n",
    "\n",
    "subD2 = D2[cols]\n",
    "subD2['D'] = np.repeat('D2',len(subD2))\n",
    "\n",
    "D3['D'] = np.repeat('D3',len(D3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Begin preprocessing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "allData = pd.concat([subD1,subD2,D3],axis=0)\n",
    "visc = allData['VISCODE'].values\n",
    "age = allData['AGE'].values\n",
    "for i,v in enumerate(visc):\n",
    "    if v.startswith('m'):\n",
    "        inc = float(v.split('m')[1])/12.\n",
    "        age[i] += inc\n",
    "allData['AGE'] = age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# infer the categorical features\n",
    "import re\n",
    "prefix = '(^\\d+(\\.\\d+)?$)'\n",
    "onehotMask = [False if re.match(prefix,str(x)) else True for x in allData.iloc[0,:].values]\n",
    "contMask = [not x for x in onehotMask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicting adas13\n",
    "onehotCols = ['PTGENDER','PTETHCAT','PTRACCAT','PTMARRY']\n",
    "contCols = ['AGE','PTEDUCAT','Hippocampus',\\\n",
    "            'WholeBrain','Entorhinal','Fusiform','MidTemp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "allData = allData.loc[~np.isnan(allData['ADAS13'].values),:]\n",
    "# lots of the records are duplicated.\n",
    "allData = allData.drop_duplicates(subset=['RID','AGE'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## preprocessing for LGPR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler,OneHotEncoder\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "contData = allData[contCols].values\n",
    "onehotData = allData[onehotCols].values\n",
    "\n",
    "scaler = StandardScaler()\n",
    "imp = IterativeImputer(max_iter=30, random_state=0)\n",
    "dataScaler = scaler.fit_transform(contData)\n",
    "dataScaler = imp.fit_transform(dataScaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorizeFeature(x):\n",
    "    idmap = {each:i for i,each in enumerate(set(x))}\n",
    "    if len(idmap) > 1:\n",
    "        return np.array([idmap[each] for each in x]).reshape(-1,1)\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "colnames = []\n",
    "cateRes = None\n",
    "for each in range(onehotData.shape[1]):\n",
    "    if cateRes is None:\n",
    "        r = categorizeFeature(onehotData[:,each])\n",
    "        if r is not None:\n",
    "            cateRes = r\n",
    "            colnames.append(onehotCols[each])\n",
    "    else:\n",
    "        r = categorizeFeature(onehotData[:,each])\n",
    "        if r is not None:\n",
    "            cateRes = np.concatenate([cateRes,r],axis=1)\n",
    "            colnames.append(onehotCols[each])\n",
    "cateCols = np.arange(len(colnames))\n",
    "colnames.extend(contCols)\n",
    "colnames = np.array(colnames)\n",
    "contCC = np.arange(len(cateCols),len(colnames))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## preprocessing for other algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "colnames = []\n",
    "onehotModel = OneHotEncoder()\n",
    "cateRes = onehotModel.fit_transform(onehotData.astype(str)).toarray()\n",
    "for i in range(len(onehotModel.categories_)):\n",
    "    colnames.extend([onehotCols[i]+'_'+str(x) for x in onehotModel.categories_[i]])\n",
    "colnames.extend(contCols)\n",
    "colnames = np.array(colnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "idCol = allData['RID'].values\n",
    "oidCol = allData['AGE'].values\n",
    "X = np.concatenate([cateRes,dataScaler],axis=1)\n",
    "y = allData['ADAS13'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# format a small dataset containing only several individuals\n",
    "from collections import Counter\n",
    "ct = Counter(idCol)\n",
    "top = 50\n",
    "targetIds = set([x[0] for x in ct.most_common()[:top]])\n",
    "mask = [x in targetIds for x in idCol]\n",
    "idCol = idCol[mask]\n",
    "oidCol = oidCol[mask]\n",
    "X = X[mask]\n",
    "y = y[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def splitTrainTest(ids, time, prop=.7, seed = 19):\n",
    "    np.random.seed(seed)\n",
    "    mask = np.array([np.random.uniform() < prop for x in ids])\n",
    "    \n",
    "    trainIdx, trainTime = ids[mask], time[mask]\n",
    "    testIdx,testTime = ids[~mask],time[~mask]\n",
    "    trainDict = defaultdict(list)\n",
    "    testDict = defaultdict(list)\n",
    "    \n",
    "    for i,m in enumerate(mask):\n",
    "        if m:\n",
    "            trainDict[ids[i]].append((time[i],i))\n",
    "        else:\n",
    "            testDict[ids[i]].append((time[i],i))\n",
    "    for k,v in trainDict.items():\n",
    "        trainV = [x[0] for x in v]\n",
    "        trainVid = [x[1] for x in v]\n",
    "        tv = testDict.get(k,None)\n",
    "        if tv is not None:\n",
    "            testV = [x[0] for x in tv]\n",
    "            testVid = [x[1] for x in tv]\n",
    "            maxId = np.argmax(trainV)\n",
    "            minId = np.argmin(testV)\n",
    "            while trainV[maxId] > testV[minId]:\n",
    "                tmp = trainV[maxId]\n",
    "                trainV[maxId] = testV[minId]\n",
    "                testV[minId] = tmp\n",
    "                tmp = trainVid[maxId]\n",
    "                trainVid[maxId] = testVid[minId]\n",
    "                testVid[minId] = tmp\n",
    "                maxId = np.argmax(trainV)\n",
    "                minId = np.argmin(testV)\n",
    "            trainDict[k] = [(x,y) for x,y in zip(trainV,trainVid)]\n",
    "            testDict[k] = [(x,y) for x,y in zip(testV,testVid)]\n",
    "    train = []\n",
    "    test = []\n",
    "    for k,v in trainDict.items():\n",
    "        train.extend([x[1] for x in v])\n",
    "    for k,v in testDict.items():\n",
    "        test.extend([x[1] for x in v])\n",
    "    return np.array(train), np.array(test)\n",
    "\n",
    "def getIndvFixFeature(ids,x):\n",
    "    dt = defaultdict(list)\n",
    "    for i,k in enumerate(ids):\n",
    "        dt[k].append(x[i])\n",
    "    noChange = np.repeat(True,x.shape[1])\n",
    "    for k,v in dt.items():\n",
    "        v = np.array(v)\n",
    "        for i in range(v.shape[1]):\n",
    "            if np.sum(v[:,i] - v[0,i]) != 0:\n",
    "                noChange[i] = False\n",
    "    return noChange\n",
    "\n",
    "from scipy import io\n",
    "def generate(seed = 19,density = 0.7,name = 'tadpole'):\n",
    "    trainIdx, testIdx = splitTrainTest(idCol, X[:,np.where(colnames == 'AGE')[0]].reshape(-1),density,seed)\n",
    "    if name == 'tadpoleLGPR':\n",
    "        io.savemat(f'../tadpoleLGPR_{seed}',{'trainId':idCol[trainIdx],'trainOid':oidCol[trainIdx],'trainX':X[trainIdx],'trainY':y[trainIdx],\n",
    "                                  'testId':idCol[testIdx],'testOid':oidCol[testIdx],'testX':X[testIdx],'testY':y[testIdx],'colname':colnames,\n",
    "                                        'cateCols':cateCols, 'contCols':contCC})\n",
    "    else:\n",
    "        io.savemat(f'../tadpole_{seed}',{'trainId':idCol[trainIdx],'trainOid':oidCol[trainIdx],'trainX':X[trainIdx],'trainY':y[trainIdx],\n",
    "                                  'testId':idCol[testIdx],'testOid':oidCol[testIdx],'testX':X[testIdx],'testY':y[testIdx],'colname':colnames})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate(seed=14,name='tadpole')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
